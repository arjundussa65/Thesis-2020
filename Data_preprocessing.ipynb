{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjundussa65/Thesis-2020/blob/master/Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIhwAout6dde",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTUTW4THQIEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f941d84c-86c3-4a8b-f940-de002ccb5019"
      },
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXPNkEj-QJkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "734eaeb5-d53b-4cae-84f2-c0b1cdc8921a"
      },
      "source": [
        "\n",
        "## load libraries\n",
        "import pandas as pd ##data manipulation\n",
        "import os           ## enables python interpreter to read os files and folders\n",
        "import nltk         ## nlp library, stemming, stopwords etc\n",
        "import string       ## enables to work on specifically on string\n",
        "import re           ## regular expression library\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACrIHI5sTHh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the datafile\n",
        "df=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/tweets.csv\",encoding=\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7SanZsUWbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "355217c0-89a9-49b3-b8af-c2e8ed7fa156"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Mentions</th>\n",
              "      <th>HashTags</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KendallHarmon6</td>\n",
              "      <td>(Stat News) ‘Speed is critical’: As #coronavir...</td>\n",
              "      <td>2020-03-01 23:59:17+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#coronavirus #USA #economy #covid19 #globalisa...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Switzercomau</td>\n",
              "      <td>The first Australian has now passed away from ...</td>\n",
              "      <td>2020-03-01 23:45:00+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#australia #ausnews #breakingnews #worldnews #...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TushK11</td>\n",
              "      <td>New York Magazine: New Coronavirus Cases Confi...</td>\n",
              "      <td>2020-03-01 23:41:02+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@googlenews</td>\n",
              "      <td>#coronavirususa #StockMarket #COVID19 #stocks</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>StockDaddy0</td>\n",
              "      <td>Still not at Friday lows but we moving. Let’s ...</td>\n",
              "      <td>2020-03-01 23:39:19+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#DoctorWho #COVID #March1st #SundayThoughts #C...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>murtdoc</td>\n",
              "      <td>Things look bleak for oil. $38.96 / barrel see...</td>\n",
              "      <td>2020-03-01 23:38:43+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Oil #stock #COVID19 #financialcrush2020</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             User  ... location\n",
              "0  KendallHarmon6  ...      NaN\n",
              "1    Switzercomau  ...      NaN\n",
              "2         TushK11  ...      NaN\n",
              "3     StockDaddy0  ...      NaN\n",
              "4         murtdoc  ...      NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5aHYX7C8ibU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  #Contraction mapping\n",
        "\n",
        "    CONTRACTION_MAP = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\",\n",
        "                       \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "                       \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\",\n",
        "                       \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                       \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                       \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\",\n",
        "                       \"he'll've\": \"he he will have\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                       \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                       \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\",\n",
        "                       \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\",\n",
        "                       \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",\n",
        "                       \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\",\n",
        "                       \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n",
        "                       \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\",\n",
        "                       \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
        "                       \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "                       \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n",
        "                       \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                       \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\",\n",
        "                       \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                       \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
        "                       \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                       \"this's\": \"this is\",\n",
        "                       \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\",\n",
        "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\",\n",
        "                       \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
        "                       \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
        "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "                       \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
        "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
        "                       \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                       \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
        "                       \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                       \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
        "                       \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n",
        "                       \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n",
        "                       \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
        "                       \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                       \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
        "                       \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
        "\n",
        "\n",
        "    def expand_contractions(sentence, contraction_mapping):\n",
        "        \"\"\"\n",
        "        description :- custom function to replace contractions in sentence\n",
        "        input  :- a sentence\n",
        "        output :- a sentence returns with replace contractions\n",
        "        \"\"\"\n",
        "        contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
        "                                          flags=re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "        def expand_match(contraction):\n",
        "            match = contraction.group(0)\n",
        "            first_char = match[0]\n",
        "            expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(\n",
        "                match) else contraction_mapping.get(match.lower())\n",
        "            expanded_contraction = first_char + expanded_contraction[1:]\n",
        "            return expanded_contraction\n",
        "\n",
        "        expanded_sentence = contractions_pattern.sub(expand_match, sentence)\n",
        "        return expanded_sentence\n",
        "    df['Text'] = df['Text'].apply(lambda x: \" \".join(expand_contractions(txt, CONTRACTION_MAP) for txt in nltk.sent_tokenize(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gETq3caDBOS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## strip of spaces in the beginning and ending\n",
        "df['Text'] = df['Text'].str.strip()\n",
        "#df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn4yYWXceWU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce7554c8-a2c9-4bf2-84c1-328bb14aa2b4"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22056, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IXTa_vmgGgQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "75c5d400-8af0-4e21-881c-5c9866bb8794"
      },
      "source": [
        "df.Text[8]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'(Axios) Scoop: Lab for #coronavirus test kits may have been contaminated https://www.axios.com/cdc-lab-coronavirus-contaminated-6dc9726d-dea3-423f-b5ad-eb7b1e44c2e2.html #economy #covid19 #globalisation #health #publichealth #china #travel #virology #publicsafety #epidemiology #viruses #21stc #corporations #workers #labs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwWxu0A5goAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to remove urls\n",
        "\n",
        "def remove_urls(text):\n",
        "    \"\"\"\n",
        "    description :- custom function to remove URL's\n",
        "    input  :- a sentence\n",
        "    output :- a sentence whose URL links is removed\n",
        "    \"\"\"\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "df['Text'] = df['Text'].apply(lambda x: remove_urls(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6iYTclcCJhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to remove https, account handles and hashtags\n",
        "\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "pat3 = r'#[A-Za-z0-9]+'\n",
        "combined_pat = r'|'.join((pat1, pat2,pat3))\n",
        "def tweet_cleaner(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped)\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lower_case = letters_only.lower()\n",
        "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
        "    # I will tokenize and join together to remove unneccessary white spaces\n",
        "    words = tok.tokenize(lower_case)\n",
        "    return (\" \".join(words)).strip()\n",
        "testing = df.Text[:22056]\n",
        "test_result = []\n",
        "for t in testing:\n",
        "    test_result.append(tweet_cleaner(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XzB764kTaT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8653ac26-e5f5-45bd-ecfa-bcf9b97dc9c5"
      },
      "source": [
        "df['Text'] = pd.DataFrame(test_result,columns=['Text'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Mentions</th>\n",
              "      <th>HashTags</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KendallHarmon6</td>\n",
              "      <td>stat news speed is critical as spreads in offi...</td>\n",
              "      <td>2020-03-01 23:59:17+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#coronavirus #USA #economy #covid19 #globalisa...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Switzercomau</td>\n",
              "      <td>the first australian has now passed away from ...</td>\n",
              "      <td>2020-03-01 23:45:00+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#australia #ausnews #breakingnews #worldnews #...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TushK11</td>\n",
              "      <td>new york magazine new coronavirus cases confir...</td>\n",
              "      <td>2020-03-01 23:41:02+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@googlenews</td>\n",
              "      <td>#coronavirususa #StockMarket #COVID19 #stocks</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>StockDaddy0</td>\n",
              "      <td>still not at friday lows but we moving let s s...</td>\n",
              "      <td>2020-03-01 23:39:19+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#DoctorWho #COVID #March1st #SundayThoughts #C...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>murtdoc</td>\n",
              "      <td>things look bleak for oil barrel seems an easy...</td>\n",
              "      <td>2020-03-01 23:38:43+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Oil #stock #COVID19 #financialcrush2020</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             User  ... location\n",
              "0  KendallHarmon6  ...      NaN\n",
              "1    Switzercomau  ...      NaN\n",
              "2         TushK11  ...      NaN\n",
              "3     StockDaddy0  ...      NaN\n",
              "4         murtdoc  ...      NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjXyB3BbvWo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "aba21b58-f592-4450-c839-315eb6c05379"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Mentions</th>\n",
              "      <th>HashTags</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22051</th>\n",
              "      <td>LadMichaelO</td>\n",
              "      <td>travel is getting a bit scary with the coronav...</td>\n",
              "      <td>2020-02-29 23:35:30+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#coronavirus #coronavirusoutbreak #covid19 #tr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22052</th>\n",
              "      <td>BusTrav</td>\n",
              "      <td>covid cases jump in iran as italy toll rises l...</td>\n",
              "      <td>2020-02-29 23:34:33+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#businesstravel #travel</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22053</th>\n",
              "      <td>Rashikede</td>\n",
              "      <td>update on covid situation in maldives no suspe...</td>\n",
              "      <td>2020-02-29 23:33:04+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#travelblogger #maldivewholidays #travel #COVI...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22054</th>\n",
              "      <td>astuteinvesting</td>\n",
              "      <td>breaking goldman sachs predicts bigger covid h...</td>\n",
              "      <td>2020-02-29 23:18:54+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#finance</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22055</th>\n",
              "      <td>TimGamble</td>\n",
              "      <td>updated at pm now cases in the us and death in...</td>\n",
              "      <td>2020-02-29 23:17:14+00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#WuhanCoronavius #COVID19 #preppers #China #ne...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  User  ... location\n",
              "22051      LadMichaelO  ...      NaN\n",
              "22052          BusTrav  ...      NaN\n",
              "22053        Rashikede  ...      NaN\n",
              "22054  astuteinvesting  ...      NaN\n",
              "22055        TimGamble  ...      NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40oc00pVi9o_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop duplicates\n",
        "df.drop_duplicates(subset=['User','Text','Date','Favorites','Retweets'],keep='first',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHXhWrZfjC66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a3c4a08-085c-436c-ab7f-d7bd76a11430"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19818, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM5v611IlLdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Removal of utf special characters\n",
        "utf_special_characs = ['xe2x80x81',\n",
        "'xe2x80x82',\n",
        "'xe2x80x83',\n",
        "'xe2x80x84',\n",
        "'xe2x80x85',\n",
        "'xe2x80x86',\n",
        "'xe2x80x87',\n",
        "'xe2x80x88',\n",
        "'xe2x80x89',\n",
        "'xe2x80x8a',\n",
        "'xe2x80x8b',\n",
        "'xe2x80x8c',\n",
        "'xe2x80x8d',\n",
        "'xe2x80x8e',\n",
        "'xe2x80x8f',\n",
        "'xe2x80x90',\n",
        "'xe2x80x91',\n",
        "'xe2x80x92',\n",
        "'xe2x80x93',\n",
        "'xe2x80x94',\n",
        "'xe2x80x95',\n",
        "'xe2x80x96',\n",
        "'xe2x80x97',\n",
        "'xe2x80x98',\n",
        "'xe2x80x99',\n",
        "'xe2x80x9a',\n",
        "'xe2x80x9b',\n",
        "'xe2x80x9c',\n",
        "'xe2x80x9d',\n",
        "'xe2x80x9e',\n",
        "'xe2x80x9f',\n",
        "'xe2x80xa0',\n",
        "'xe2x80xa1',\n",
        "'xe2x80xa2',\n",
        "'xe2x80xa3',\n",
        "'xe2x80xa4',\n",
        "'xe2x80xa5',\n",
        "'xe2x80xa6',\n",
        "'xe2x80xa7',\n",
        "'xe2x80xa8',\n",
        "'xe2x80xa9',\n",
        "'xe2x80xaa',\n",
        "'xe2x80xab',\n",
        "'xe2x80xac',\n",
        "'xe2x80xad',\n",
        "'xe2x80xae',\n",
        "'xe2x80xaf',\n",
        "'xe2x80xb0',\n",
        "'xe2x80xb1',\n",
        "'xe2x80xb2',\n",
        "'xe2x80xb3',\n",
        "'xe2x80xb4',\n",
        "'xe2x80xb5',\n",
        "'xe2x80xb6',\n",
        "'xe2x80xb7',\n",
        "'xe2x80xb8',\n",
        "'xe2x80xb9',\n",
        "'xe2x80xba',\n",
        "'xe2x80xbb',\n",
        "'xe2x80xbc',\n",
        "'xe2x80xbd',\n",
        "'xe2x80xbe',\n",
        "'xe2x80xbf',\n",
        "'xe2x81x80',\n",
        "'xe2x81x81',\n",
        "'xe2x81x82',\n",
        "'xe2x81x83',\n",
        "'xe2x81x84',\n",
        "'xe2x81x85',\n",
        "'xe2x81x86',\n",
        "'xe2x81x87',\n",
        "'xe2x81x88',\n",
        "'xe2x81x89',\n",
        "'xe2x81x8a',\n",
        "'xe2x81x8b',\n",
        "'xe2x81x8c',\n",
        "'xe2x81x8d',\n",
        "'xe2x81x8e',\n",
        "'xe2x81x8f',\n",
        "'xe2x81x90',\n",
        "'xe2x81x91',\n",
        "'xe2x81x92',\n",
        "'xe2x81x93',\n",
        "'xe2x81x94',\n",
        "'xe2x81x95',\n",
        "'xe2x81x96',\n",
        "'xe2x81x97',\n",
        "'xe2x81x98',\n",
        "'xe2x81x99',\n",
        "'xe2x81x9a',\n",
        "'xe2x81x9b',\n",
        "'xe2x81x9c',\n",
        "'xe2x81x9d',\n",
        "'xe2x81x9e',\n",
        "'xe2x81x9f',\n",
        "'xe2x81xa0',\n",
        "'xe2x81xa1',\n",
        "'xe2x81xa2',\n",
        "'xe2x81xa3',\n",
        "'xe2x81xa4',\n",
        "'xe2x81xa5',\n",
        "'xe2x81xa6',\n",
        "'xe2x81xa7',\n",
        "'xe2x81xa8',\n",
        "'xe2x81xa9',\n",
        "'xe2x81xaa',\n",
        "'xe2x81xab',\n",
        "'xe2x81xac',\n",
        "'xe2x81xad',\n",
        "'xe2x81xae',\n",
        "'xe2x81xaf',\n",
        "'xe2x81xb0',\n",
        "'xe2x81xb1',\n",
        "'xe2x81xb2',\n",
        "'xe2x81xb3',\n",
        "'xe2x81xb4',\n",
        "'xe2x81xb5',\n",
        "'xe2x81xb6',\n",
        "'xe2x81xb7',\n",
        "'xe2x81xb8',\n",
        "'xe2x81xb9',\n",
        "'xe2x81xba',\n",
        "'xe2x81xbb',\n",
        "'xe2x81xbc',\n",
        "'xe2x81xbd',\n",
        "'xe2x81xbe',\n",
        "'xe2x81xbf']\n",
        "\n",
        "def remove_special_chars(x):\n",
        "    \"\"\"\n",
        "    description :- custom function to remove utf special chars\n",
        "    input  :- a sentence\n",
        "    output :- a sentence returns after removal of  utf special chars\n",
        "    \"\"\"\n",
        "    vals = []\n",
        "    for val in x.split(\" \"):\n",
        "        for utf_val in utf_special_characs:\n",
        "            val = re.sub(utf_val,\"\",val)\n",
        "            if re.search(\"x..x..*\", val) == None:\n",
        "                vals.append(val)\n",
        "                break\n",
        "            continue\n",
        "    return \" \".join(val for val in vals)\n",
        "df['Text'] = df['Text'].apply(lambda x: remove_special_chars(x))\n",
        "\n",
        "def only_chars(x):\n",
        "    \"\"\" keep only characters \"\"\"\n",
        "    return re.sub('[^a-zA-Z]+', ' ', x)\n",
        "only_chars(\"abc 123 abc\")\n",
        "df['Text'] = df['Text'].apply(lambda x: only_chars(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoBYDWQnjKyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a01b315b-6853-4c87-a50a-c672626c3df1"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User</th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Mentions</th>\n",
              "      <th>HashTags</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22047</th>\n",
              "      <td>grumpysteward</td>\n",
              "      <td>i will likely be taking advantage of the cheap...</td>\n",
              "      <td>2020-02-28 23:55:05+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#grumpystew #covid #travelnews #stockprices</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22048</th>\n",
              "      <td>stock_fairy</td>\n",
              "      <td>if the keep falling how confident will you be ...</td>\n",
              "      <td>2020-02-28 23:54:39+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#stockmarkets #vaccine #COVID</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22050</th>\n",
              "      <td>BusTrav</td>\n",
              "      <td>covid cancels more than flights to from and wi...</td>\n",
              "      <td>2020-02-28 23:35:28+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#businesstravel #travel</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22052</th>\n",
              "      <td>BusTrav</td>\n",
              "      <td>covid cases jump in iran as italy toll rises l...</td>\n",
              "      <td>2020-02-29 23:34:33+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#businesstravel #travel</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22054</th>\n",
              "      <td>astuteinvesting</td>\n",
              "      <td>breaking goldman sachs predicts bigger covid h...</td>\n",
              "      <td>2020-02-29 23:18:54+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#finance</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  User  ... location\n",
              "22047    grumpysteward  ...      NaN\n",
              "22048      stock_fairy  ...      NaN\n",
              "22050          BusTrav  ...      NaN\n",
              "22052          BusTrav  ...      NaN\n",
              "22054  astuteinvesting  ...      NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETdXnnJdlk-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "f307c827-bd2a-4f5a-bd02-1335986082a2"
      },
      "source": [
        "#Remove null values in the text field and reset index\n",
        "df.dropna(subset=['Text'],inplace=True)  # Removed the Null values from Tweet_text column\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19818 entries, 0 to 19817\n",
            "Data columns (total 8 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   User       19818 non-null  object \n",
            " 1   Text       19818 non-null  object \n",
            " 2   Date       19818 non-null  object \n",
            " 3   Favorites  19818 non-null  int64  \n",
            " 4   Retweets   19818 non-null  int64  \n",
            " 5   Mentions   4320 non-null   object \n",
            " 6   HashTags   19806 non-null  object \n",
            " 7   location   0 non-null      float64\n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHG_Pvx-RLrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving cleaned tweets to a file\n",
        "df.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/covid_cleaned.csv\", index=None, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4m19aGMg9Hl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "66c49aaf-4291-4f72-99a8-1b3fe589b314"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19818 entries, 0 to 19817\n",
            "Data columns (total 8 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   User       19818 non-null  object \n",
            " 1   Text       19818 non-null  object \n",
            " 2   Date       19818 non-null  object \n",
            " 3   Favorites  19818 non-null  int64  \n",
            " 4   Retweets   19818 non-null  int64  \n",
            " 5   Mentions   4320 non-null   object \n",
            " 6   HashTags   19806 non-null  object \n",
            " 7   location   0 non-null      float64\n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8XhNOlgmCFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}