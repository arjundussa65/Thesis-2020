{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNET with undersampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdc50e136e7d49c9861f07d4d8fce734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87087d0340d5442d980f774d06d641dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d3568dec1224198a3fccba1ddf2d656",
              "IPY_MODEL_f6a9ba097881489398852dad8621c6ba"
            ]
          }
        },
        "87087d0340d5442d980f774d06d641dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d3568dec1224198a3fccba1ddf2d656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd1e3239edc04c76bb60bc227f0fbcc1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_000d3c12e0f0485381ae41c7a00d9117"
          }
        },
        "f6a9ba097881489398852dad8621c6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fde610437b154b6c8b268a83893deab0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760/760 [00:13&lt;00:00, 54.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70b2976d64f14cc892fd3d34023f57e4"
          }
        },
        "fd1e3239edc04c76bb60bc227f0fbcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "000d3c12e0f0485381ae41c7a00d9117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fde610437b154b6c8b268a83893deab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70b2976d64f14cc892fd3d34023f57e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "505ffca9993247629b8009d8dab169da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e27183947564424eb300850cfc4c6729",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e945b5df0e1c4fbfb35721a8b66e8624",
              "IPY_MODEL_a6e23aa96a70421daf026c7dcaf9c104"
            ]
          }
        },
        "e27183947564424eb300850cfc4c6729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e945b5df0e1c4fbfb35721a8b66e8624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_536e1b301a5444658fc5d17fb50bd0cc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467042463,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467042463,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac51194989cb43f8b3e92b10b01e5fea"
          }
        },
        "a6e23aa96a70421daf026c7dcaf9c104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f376cc8b78014c47ad60a6f3f1e17a99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467M/467M [00:13&lt;00:00, 33.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8db1eb528b84379bce844fc968bc501"
          }
        },
        "536e1b301a5444658fc5d17fb50bd0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac51194989cb43f8b3e92b10b01e5fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f376cc8b78014c47ad60a6f3f1e17a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8db1eb528b84379bce844fc968bc501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjundussa65/Thesis-2020/blob/master/XLNET_with_undersampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmo-kT4oZcUG",
        "colab_type": "text"
      },
      "source": [
        "# XLNet Finetuning with Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nePX7bzmZiaS",
        "colab_type": "text"
      },
      "source": [
        "This section of the file contains XLNet finetuning with dropout regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ_AKgEsyiAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "77b808f6-41e8-45cb-f7b0-4f7ec73ffe56"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=962f2f54d3f6418c3e3a408745d02f3f053ed3cd303f64724e52d2412dbf67af\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X46aVyKayk4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "56f587f9-df22-47bf-9d1b-26464b4957da"
      },
      "source": [
        "#mount google drive for colab usage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATLGlQYFymcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the necessary libraries \n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import os\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from torch.autograd.function import InplaceFunction\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn import Parameter\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS8gZ69Oyri9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6c00b8dc-d535-4821-be0c-ff4670c9043a"
      },
      "source": [
        "\n",
        "#For GPU usage\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNhlmddAywJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read file from Google Drive\n",
        "df=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/covid_labelled.csv\", encoding='utf-8',usecols=['Text','Num_Sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSgdB0Eyy1U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mapping labels\n",
        "df.loc[:,'sentiment'] = df.Num_Sentiment.map({-1:2,0:0,1:1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oibsBmfry226",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c06a1479-8c2d-4f45-acbc-162105c34a0c"
      },
      "source": [
        "#Undersample the data \n",
        "\n",
        "X = df.Text.values.reshape(-1,1)\n",
        "y = df.sentiment.values.reshape(-1,1)\n",
        "\n",
        "\n",
        "sampler = RandomUnderSampler(ratio={0:3000,1:3000,2:3000})\n",
        "X_rs, y_rs = sampler.fit_resample(X, y)\n",
        "\n",
        "X=X_rs.flatten()\n",
        "y=y_rs.flatten()\n",
        "\n",
        "#X_train, X_val, y_train, y_val =\\\n",
        " #   train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "#X_val, X_test, y_val, y_test =\\\n",
        " #   train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDEb46Tdy4Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l=np.array([X,y])\n",
        "df = pd.DataFrame({'Text': X, 'sentiment': y}, columns=['Text', 'sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFst9-c8zOck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5eee12dd-0160-4702-ad5e-a13690f83740"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>why am i not surprised dex j americans demand ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>scientists start connecting the dots from the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thank you for all who voted tell us your crazi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>check out our interview with at the link below</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will virtual dating outlast the pandemic via ht</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  sentiment\n",
              "0  why am i not surprised dex j americans demand ...          0\n",
              "1  scientists start connecting the dots from the ...          0\n",
              "2  thank you for all who voted tell us your crazi...          0\n",
              "3     check out our interview with at the link below          0\n",
              "4    will virtual dating outlast the pandemic via ht          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gID57G8z1zs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4e2d52a0-1e5d-4ffd-9baa-6a136dff0b32"
      },
      "source": [
        "#One hot encoding of target labels\n",
        "one_hot = pd.get_dummies(df[\"sentiment\"])\n",
        "df.drop(['sentiment'],axis=1,inplace=True)\n",
        "df = pd.concat([df,one_hot],axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>why am i not surprised dex j americans demand ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>scientists start connecting the dots from the ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thank you for all who voted tell us your crazi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>check out our interview with at the link below</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will virtual dating outlast the pandemic via ht</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  0  1  2\n",
              "0  why am i not surprised dex j americans demand ...  1  0  0\n",
              "1  scientists start connecting the dots from the ...  1  0  0\n",
              "2  thank you for all who voted tell us your crazi...  1  0  0\n",
              "3     check out our interview with at the link below  1  0  0\n",
              "4    will virtual dating outlast the pandemic via ht  1  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y4nqUgxzQon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split data into train and test\n",
        "\n",
        "train,test =\\\n",
        "    train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNypwRf5zSYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for tokenizer\n",
        "def plot_sentence_embeddings_length(text_list, tokenizer):\n",
        "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t), text_list))\n",
        "    tokenized_texts_len = list(map(lambda t: len(t), tokenized_texts))\n",
        "    fig, ax = plt.subplots(figsize=(8, 5));\n",
        "    ax.hist(tokenized_texts_len, bins=40);\n",
        "    ax.set_xlabel(\"Length of Comment Embeddings\");\n",
        "    ax.set_ylabel(\"Number of Comments\");\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSOyb8M1zT1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize tokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5KMiRctzV7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text_list = train[\"Text\"].values\n",
        "test_text_list = test[\"Text\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QzcfHrozXh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "c79fbcd9-b44d-4d0a-f0cf-359bc00ed44f"
      },
      "source": [
        "plot_sentence_embeddings_length(train_text_list, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip8tKW8YzY8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "3430fb08-f942-425b-f140-215b6ca89f49"
      },
      "source": [
        "plot_sentence_embeddings_length(test_text_list, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTBS9Dkkza43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_inputs(text_list, tokenizer, num_embeddings=512):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text input into ids. Appends the appropriate special\n",
        "    characters to the end of the text to denote end of sentence. Truncate or pad\n",
        "    the appropriate sequence length.\n",
        "    \"\"\"\n",
        "    # tokenize the text, then truncate sequence to the desired length minus 2 for\n",
        "    # the 2 special characters\n",
        "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:num_embeddings-2], text_list))\n",
        "    # convert tokenized text into numeric ids for the appropriate LM\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    # append special token \"<s>\" and </s> to end of sentence\n",
        "    input_ids = [tokenizer.build_inputs_with_special_tokens(x) for x in input_ids]\n",
        "    # pad sequences\n",
        "    input_ids = pad_sequences(input_ids, maxlen=num_embeddings, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    return input_ids\n",
        "\n",
        "def create_attn_masks(input_ids):\n",
        "    \"\"\"\n",
        "    Create attention masks to tell model whether attention should be applied to\n",
        "    the input id tokens. Do not want to perform attention on padding tokens.\n",
        "    \"\"\"\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aoia8pRqzcpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "67a5cf38-8d79-424c-e30c-6521c02eebc7"
      },
      "source": [
        "# create input id tokens\n",
        "train_input_ids = tokenize_inputs(train_text_list, tokenizer, num_embeddings=90)\n",
        "train_input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   36,    27, 13219, ...,     0,     0,     0],\n",
              "       [ 4242,    17,    23, ...,     0,     0,     0],\n",
              "       [  108,    17, 18576, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  319,   907,  1772, ...,     0,     0,     0],\n",
              "       [  149,    63,   154, ...,     0,     0,     0],\n",
              "       [   24,  5421,   117, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLe0etdKzgMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "772db64c-8844-40d0-b29b-2b90b43479d9"
      },
      "source": [
        "# create input id tokens\n",
        "test_input_ids = tokenize_inputs(test_text_list, tokenizer, num_embeddings=90)\n",
        "test_input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  611,    41,   463, ...,     0,     0,     0],\n",
              "       [  281,   454,  1674, ...,     0,     0,     0],\n",
              "       [  293,   546,    21, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [ 3466,    34,   426, ...,     0,     0,     0],\n",
              "       [ 4755,    28,   830, ...,     0,     0,     0],\n",
              "       [   17, 29316, 13738, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBuawf8Mzh0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create attention masks\n",
        "train_attention_masks = create_attn_masks(train_input_ids)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ7VWlMQzjp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create attention masks\n",
        "test_attention_masks = create_attn_masks(test_input_ids)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb0_LxEBzlF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "c46ab3c9-c81a-4990-fab5-b1eb614525b1"
      },
      "source": [
        "# add input ids and attention masks to the dataframe\n",
        "train[\"features\"] = train_input_ids.tolist()\n",
        "train[\"masks\"] = train_attention_masks\n",
        "\n",
        "test[\"features\"] = test_input_ids.tolist()\n",
        "test[\"masks\"] = test_attention_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGb9bwlGzmyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1d511590-003e-487d-fa84-0d26a22cb893"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>features</th>\n",
              "      <th>masks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6317</th>\n",
              "      <td>it is unfortunately because of the and fewer p...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[36, 27, 13219, 149, 20, 18, 21, 4801, 104, 53...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>absolutely suffocating hot temperatures compli...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[4242, 17, 23, 7276, 3374, 2076, 1606, 6976, 2...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3781</th>\n",
              "      <td>if ibio succeeds it will solve a major humanit...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[108, 17, 18576, 155, 5402, 23, 36, 53, 4929, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7850</th>\n",
              "      <td>very irresponsible messaging from john rogers ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[172, 24605, 19534, 40, 17, 22116, 17, 17453, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2963</th>\n",
              "      <td>anti microbial so you never need to wash your ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[932, 17, 27129, 102, 44, 287, 214, 22, 8940, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ...                                              masks\n",
              "6317  it is unfortunately because of the and fewer p...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "740   absolutely suffocating hot temperatures compli...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "3781  if ibio succeeds it will solve a major humanit...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "7850  very irresponsible messaging from john rogers ...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "2963  anti microbial so you never need to wash your ...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYqOkOr6zprn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e35daba3-ba82-48b7-81fb-abbd87674744"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>features</th>\n",
              "      <th>masks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7940</th>\n",
              "      <td>why are companies in your area like ripping pe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[611, 41, 463, 25, 73, 290, 115, 26889, 104, 1...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>public health officer defends face covering order</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[281, 454, 1674, 4567, 23, 423, 4379, 374, 4, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>little news and pie</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[293, 546, 21, 11703, 4, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4081</th>\n",
              "      <td>creative sweet hashtag face masks two filters ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[3932, 3353, 51, 409, 10585, 423, 17568, 87, 1...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412</th>\n",
              "      <td>this book is so scary the truth is always scar...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[52, 522, 27, 102, 13243, 18, 2092, 27, 426, 1...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ...                                              masks\n",
              "7940  why are companies in your area like ripping pe...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "1162  public health officer defends face covering order  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "582                                 little news and pie  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...\n",
              "4081  creative sweet hashtag face masks two filters ...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "8412  this book is so scary the truth is always scar...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE_1VJvDzqwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train valid split\n",
        "train, valid = train_test_split(train, test_size=0.4, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNm8t90iz_8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train[\"features\"].values.tolist()\n",
        "X_valid = valid[\"features\"].values.tolist()\n",
        "\n",
        "train_masks = train[\"masks\"].values.tolist()\n",
        "valid_masks = valid[\"masks\"].values.tolist()\n",
        "\n",
        "label_cols = [0,1,2]\n",
        "Y_train = train[label_cols].values.tolist()\n",
        "Y_valid = valid[label_cols].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOmrH_ER0BwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our input ids and attention masks into \n",
        "# torch tensors, the required datatype for our model\n",
        "\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "\n",
        "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
        "Y_valid = torch.tensor(Y_valid, dtype=torch.float32)\n",
        "\n",
        "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
        "valid_masks = torch.tensor(valid_masks, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKW1SHsx0cL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on \n",
        "# memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(X_train, train_masks, Y_train)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data,\\\n",
        "                              sampler=train_sampler,\\\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(X_valid, valid_masks, Y_valid)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,\\\n",
        "                                   sampler=validation_sampler,\\\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igiD4Wrz0d2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to train the model. \n",
        "\n",
        "def train(model, num_epochs,\\\n",
        "          optimizer,\\\n",
        "          train_dataloader, valid_dataloader,\\\n",
        "          model_save_path,\\\n",
        "          train_loss_set=[], valid_loss_set = [],\\\n",
        "          lowest_eval_loss=None, start_epoch=0,\\\n",
        "          device=\"cpu\"\n",
        "          ):\n",
        "  \"\"\"\n",
        "  Train the model and save the model with the lowest validation loss\n",
        "  \"\"\"\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  # trange is a tqdm wrapper around the normal python range\n",
        "  for i in trange(num_epochs, desc=\"Epoch\"):\n",
        "    # if continue training from saved model\n",
        "    actual_epoch = start_epoch + i\n",
        "\n",
        "    # Training\n",
        "\n",
        "    # Set our model to training mode (as opposed to evaluation mode)\n",
        "    model.train()\n",
        "\n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    num_train_samples = 0\n",
        "\n",
        "    # Train the data for one epoch\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      # Clear out the gradients (by default they accumulate)\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "      # store train loss\n",
        "      tr_loss += loss.item()\n",
        "      num_train_samples += b_labels.size(0)\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      # Update parameters and take a step using the computed gradient\n",
        "      optimizer.step()\n",
        "      #scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    epoch_train_loss = tr_loss/num_train_samples\n",
        "    train_loss_set.append(epoch_train_loss)\n",
        "\n",
        "    print(\"Train loss: {}\".format(epoch_train_loss))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss = 0\n",
        "    num_eval_samples = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in valid_dataloader:\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      # Telling the model not to compute or store gradients,\n",
        "      # saving memory and speeding up validation\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate validation loss\n",
        "        loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        # store valid loss\n",
        "        eval_loss += loss.item()\n",
        "        num_eval_samples += b_labels.size(0)\n",
        "\n",
        "    epoch_eval_loss = eval_loss/num_eval_samples\n",
        "    valid_loss_set.append(epoch_eval_loss)\n",
        "\n",
        "    print(\"Valid loss: {}\".format(epoch_eval_loss))\n",
        "\n",
        "    if lowest_eval_loss == None:\n",
        "      lowest_eval_loss = epoch_eval_loss\n",
        "      # save model\n",
        "      save_model(model, model_save_path, actual_epoch,\\\n",
        "                 lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    else:\n",
        "      if epoch_eval_loss < lowest_eval_loss:\n",
        "        lowest_eval_loss = epoch_eval_loss\n",
        "        # save model\n",
        "        save_model(model, model_save_path, actual_epoch,\\\n",
        "                   lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  return model, train_loss_set, valid_loss_set\n",
        "\n",
        "\n",
        "def save_model(model, save_path, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist):\n",
        "  \"\"\"\n",
        "  Save the model to the path directory provided\n",
        "  \"\"\"\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model\n",
        "  checkpoint = {'epochs': epochs, \\\n",
        "                'lowest_eval_loss': lowest_eval_loss,\\\n",
        "                'state_dict': model_to_save.state_dict(),\\\n",
        "                'train_loss_hist': train_loss_hist,\\\n",
        "                'valid_loss_hist': valid_loss_hist\n",
        "               }\n",
        "  torch.save(checkpoint, save_path)\n",
        "  print(\"Saving model at epoch {} with validation loss of {}\".format(epochs,\\\n",
        "                                                                     lowest_eval_loss))\n",
        "  return\n",
        "  \n",
        "def load_model(save_path):\n",
        "  \"\"\"\n",
        "  Load the model from the path directory provided\n",
        "  \"\"\"\n",
        "  checkpoint = torch.load(save_path)\n",
        "  model_state_dict = checkpoint['state_dict']\n",
        "  model = XLNetForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
        "  model.load_state_dict(model_state_dict)\n",
        "\n",
        "  epochs = checkpoint[\"epochs\"]\n",
        "  lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
        "  train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
        "  valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
        "  \n",
        "  return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt5Gluoo0hC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1I78LJw0k_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mixout code which mixes vanilla network and dropout\n",
        "\n",
        "class Mixout(InplaceFunction):\n",
        "    # target: a weight tensor mixes with a input tensor\n",
        "    # A forward method returns \n",
        "    # [(1 - Bernoulli(1 - p) mask) * target + (Bernoulli(1 - p) mask) * input - p * target]/(1 - p) \n",
        "    # where p is a mix probability of mixout.\n",
        "    # A backward returns the gradient of the forward method.\n",
        "    # Dropout is equivalent to the case of target=None. \n",
        "    # I modified the code of dropout in PyTorch. \n",
        "    @staticmethod\n",
        "    def _make_noise(input):\n",
        "        return input.new().resize_as_(input)\n",
        "\n",
        "    @classmethod\n",
        "    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n",
        "        if p < 0 or p > 1:\n",
        "            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\"\n",
        "                             \" but got {}\".format(p))\n",
        "        if target is not None and input.size() != target.size():\n",
        "            raise ValueError(\"A target tensor size must match with a input tensor size {},\"\n",
        "                             \" but got {}\". format(input.size(), target.size()))\n",
        "        ctx.p = p    \n",
        "        ctx.training = training\n",
        "        \n",
        "        if target is None:\n",
        "            target = cls._make_noise(input)\n",
        "            target.fill_(0)\n",
        "        target = target.to(input.device)\n",
        "\n",
        "        if inplace:\n",
        "            ctx.mark_dirty(input)\n",
        "            output = input\n",
        "        else:\n",
        "            output = input.clone()\n",
        "        \n",
        "        if ctx.p == 0 or not ctx.training:\n",
        "            return output\n",
        "        \n",
        "        ctx.noise = cls._make_noise(input)\n",
        "        if len(ctx.noise.size()) == 1:\n",
        "            ctx.noise.bernoulli_(1 - ctx.p)\n",
        "        else:\n",
        "            ctx.noise[0].bernoulli_(1 - ctx.p)\n",
        "            ctx.noise = ctx.noise[0].repeat(input.size()[0], *([1] * (len(input.size())-1)))\n",
        "        ctx.noise.expand_as(input)\n",
        "        \n",
        "        if ctx.p == 1:\n",
        "            output = target.clone()\n",
        "        else:\n",
        "            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n",
        "        return output\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        if ctx.p > 0 and ctx.training:\n",
        "            return grad_output * ctx.noise, None, None, None, None\n",
        "        else:\n",
        "            return grad_output, None, None, None, None\n",
        "\n",
        "def mixout(input, target=None, p=0.0, training=False, inplace=False):\n",
        "    return Mixout.apply(input, target, p, training, inplace)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3-1Tupw0roX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mixlinear module function\n",
        "\n",
        "#from mixout import mixout\n",
        "\n",
        "class MixLinear(torch.nn.Module):\n",
        "    __constants__ = ['bias', 'in_features', 'out_features']\n",
        "    # If target is None, nn.Sequential(nn.Linear(m, n), MixLinear(m', n', p)) \n",
        "    # is equivalent to nn.Sequential(nn.Linear(m, n), nn.Dropout(p), nn.Linear(m', n')).\n",
        "    # If you want to change a dropout layer to a mixout layer, \n",
        "    # you should replace nn.Linear right after nn.Dropout(p) with Mixout(p) \n",
        "    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n",
        "        super(MixLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "        self.target = target\n",
        "        self.p = p\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "            \n",
        "    def forward(self, input):\n",
        "        return F.linear(input, mixout(self.weight, self.target, \n",
        "                                      self.p, self.training), self.bias)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        type = 'drop' if self.target is None else 'mix' \n",
        "        return '{}={}, in_features={}, out_features={}, bias={}'.format(type+\"out\", self.p,\n",
        "            self.in_features, self.out_features, self.bias is not None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b4WhkOE0uA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cdc50e136e7d49c9861f07d4d8fce734",
            "87087d0340d5442d980f774d06d641dc",
            "3d3568dec1224198a3fccba1ddf2d656",
            "f6a9ba097881489398852dad8621c6ba",
            "fd1e3239edc04c76bb60bc227f0fbcc1",
            "000d3c12e0f0485381ae41c7a00d9117",
            "fde610437b154b6c8b268a83893deab0",
            "70b2976d64f14cc892fd3d34023f57e4",
            "505ffca9993247629b8009d8dab169da",
            "e27183947564424eb300850cfc4c6729",
            "e945b5df0e1c4fbfb35721a8b66e8624",
            "a6e23aa96a70421daf026c7dcaf9c104",
            "536e1b301a5444658fc5d17fb50bd0cc",
            "ac51194989cb43f8b3e92b10b01e5fea",
            "f376cc8b78014c47ad60a6f3f1e17a99",
            "a8db1eb528b84379bce844fc968bc501"
          ]
        },
        "outputId": "5ce36bb3-6623-435a-a2ec-aa25bb95c49e"
      },
      "source": [
        "#Initializee XLNet model and add classifier \n",
        "        \n",
        "class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, num_labels=2):\n",
        "    super(XLNetForMultiLabelSequenceClassification, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    # Instantiate an one-layer feed-forward classifier\n",
        "    self.classifier = self.classifier= nn.Linear(768, num_labels)\n",
        "    \n",
        "\n",
        "    torch.nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels=None):\n",
        "    # last hidden layer\n",
        "    last_hidden_state = self.xlnet(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "    # pool the outputs into a mean vector\n",
        "    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
        " #   mean_last_hidden_state = self.activation(mean_last_hidden_state)\n",
        " #   mean_last_hidden_state = self.dropout(mean_last_hidden_state)\n",
        "    logits = self.classifier(mean_last_hidden_state)\n",
        "        \n",
        "    if labels is not None:\n",
        "      loss_fct = BCEWithLogitsLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels),\\\n",
        "                      labels.view(-1, self.num_labels))\n",
        "      return loss\n",
        "    else:\n",
        "      return logits\n",
        "    \n",
        "  def freeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Freeze XLNet weight parameters. They will not be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = False\n",
        "    \n",
        "  def unfreeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Unfreeze XLNet weight parameters. They will be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = True\n",
        "    \n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector \n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "    \n",
        "model2 = XLNetForMultiLabelSequenceClassification(num_labels=len(Y_train[0]))\n",
        "#model = torch.nn.DataParallel(model)\n",
        "model2.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdc50e136e7d49c9861f07d4d8fce734",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "505ffca9993247629b8009d8dab169da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForMultiLabelSequenceClassification(\n",
              "  (xlnet): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (classifier): MixLinear(dropout=0.5, in_features=768, out_features=3, bias=True)\n",
              "  (activation): ELU(alpha=1.0)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuh9Ozpz2FL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize optimizer\n",
        "optimizer = AdamW(model2.parameters(), lr=2e-5, weight_decay=0.01, correct_bias=False)\n",
        "#scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)  # PyTorch scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIY8uITF2JCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "8c3aff77-8c75-4039-eb17-097895707f0d"
      },
      "source": [
        "#Define training epocs and train the model\n",
        "num_epochs=2\n",
        "\n",
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"gdrive/My Drive/Colab Notebooks/xlnet_tweet_undersamp.bin\")\n",
        "model, train_loss_set, valid_loss_set = train(model=model2,\\\n",
        "                                              num_epochs=num_epochs,\\\n",
        "                                              optimizer=optimizer,\\\n",
        "                                              train_dataloader=train_dataloader,\\\n",
        "                                              valid_dataloader=validation_dataloader,\\\n",
        "                                              model_save_path=model_save_path,\\\n",
        "                                              device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.023685469174826588\n",
            "Valid loss: 0.019700101928578483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 1/2 [03:40<03:40, 220.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model at epoch 0 with validation loss of 0.019700101928578483\n",
            "\n",
            "\n",
            "Train loss: 0.018241517197478702\n",
            "Valid loss: 0.014596843998879195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 2/2 [07:17<00:00, 218.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model at epoch 1 with validation loss of 0.014596843998879195\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK3DEGEv2Xxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "64c01830-e2a4-43c1-b819-75fab12767ee"
      },
      "source": [
        "# Plot loss vs number of epochs\n",
        "num_epochs = np.arange(len(train_loss_set))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5));\n",
        "ax.plot(num_epochs, np.array(train_loss_set), label=\"Train Loss\")\n",
        "ax.plot(num_epochs, np.array(valid_loss_set), 'g-', label=\"Valid Loss\")\n",
        "#ax1.plot(episode_record, lose_record, 'r-', label=\"Lose %\")\n",
        "ax.set_xlabel(\"Number of Epochs\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.set_title(\"Loss vs Number of Epochs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs Number of Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZa43n6I4VgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"gdrive/My Drive/Colab Notebooks/xlnet_tweet_undersamp.bin\")\n",
        "model, start_epoch, lowest_eval_loss, train_loss_hist, valid_loss_hist = load_model(model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuYy1H2z49Jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to predict the model on test data\n",
        "def generate_predictions(model, df, num_labels, device=\"cpu\", batch_size=32):\n",
        "  num_iter = math.ceil(df.shape[0]/batch_size)\n",
        "  \n",
        "  pred_probs = np.array([]).reshape(0, num_labels)\n",
        "  \n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  \n",
        "  for i in range(num_iter):\n",
        "    df_subset = df.iloc[i*batch_size:(i+1)*batch_size,:]\n",
        "    X = df_subset[\"features\"].values.tolist()\n",
        "    masks = df_subset[\"masks\"].values.tolist()\n",
        "    X = torch.tensor(X)\n",
        "    masks = torch.tensor(masks, dtype=torch.long)\n",
        "    X = X.to(device)\n",
        "    masks = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "      logits = model(input_ids=X, attention_mask=masks)\n",
        "      logits = logits.sigmoid().detach().cpu().numpy()\n",
        "      pred_probs = np.vstack([pred_probs, logits])\n",
        "  \n",
        "  return pred_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8LOZJ9c4-8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = len(label_cols)\n",
        "pred_probs = generate_predictions(model, test, num_labels, device=\"cuda\", batch_size=32)\n",
        "pred_probs=np.round(pred_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEgJyVXX9pO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1a27f337-582a-48d9-e125-228841dfc3bc"
      },
      "source": [
        "pred_probs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2SeL-425Avd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=np.round(pred_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jGtp2q15hp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f9fee6b6-b489-472c-8429-a390fc3e9896"
      },
      "source": [
        "#Print accuracy score\n",
        "y_test=test.iloc[:,1:4].values\n",
        "accuracy_score(y_test,a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7940</th>\n",
              "      <td>why are companies in your area like ripping pe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>public health officer defends face covering order</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>little news and pie</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4081</th>\n",
              "      <td>creative sweet hashtag face masks two filters ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412</th>\n",
              "      <td>this book is so scary the truth is always scar...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  0  ...  Positive  Negative\n",
              "7940  why are companies in your area like ripping pe...  0  ...       0.0       1.0\n",
              "1162  public health officer defends face covering order  1  ...       0.0       0.0\n",
              "582                                 little news and pie  1  ...       0.0       0.0\n",
              "4081  creative sweet hashtag face masks two filters ...  0  ...       1.0       0.0\n",
              "8412  this book is so scary the truth is always scar...  0  ...       0.0       1.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBWHljb_bp6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Print classification report\n",
        "print('\\nClassification Report\\n')\n",
        "y_pred=np.round(pred_probs)\n",
        "print(classification_report(y_test, a, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvqYbakbbsXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Print confusion matrix\n",
        "print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12fqDschbtlk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Finetune XLNet with Mixout Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tK4CcDS-DnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize XLNet model for multiclass classification and add classifier and convert the linear layer to mixlinear with mixout percentage added \n",
        "        \n",
        "class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, num_labels=2):\n",
        "    super(XLNetForMultiLabelSequenceClassification, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    # Instantiate an one-layer feed-forward classifier\n",
        "    self.classifier = torch.nn.Linear(768, num_labels)\n",
        "    \n",
        "\n",
        "    torch.nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels=None):\n",
        "    # last hidden layer\n",
        "    last_hidden_state = self.xlnet(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "    # pool the outputs into a mean vector\n",
        "    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
        " #   mean_last_hidden_state = self.activation(mean_last_hidden_state)\n",
        " #   mean_last_hidden_state = self.dropout(mean_last_hidden_state)\n",
        "    logits = self.classifier(mean_last_hidden_state)\n",
        "        \n",
        "    if labels is not None:\n",
        "      loss_fct = BCEWithLogitsLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels),\\\n",
        "                      labels.view(-1, self.num_labels))\n",
        "      return loss\n",
        "    else:\n",
        "      return logits\n",
        "    \n",
        "  def freeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Freeze XLNet weight parameters. They will not be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = False\n",
        "    \n",
        "  def unfreeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Unfreeze XLNet weight parameters. They will be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = True\n",
        "    \n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector \n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "    \n",
        "model3 = XLNetForMultiLabelSequenceClassification(num_labels=len(Y_train[0]))\n",
        "for name, module in model3.named_modules():\n",
        "    if name in ['dropout'] and isinstance(module, nn.Dropout):\n",
        "        setattr(model3, name, nn.Dropout(0))\n",
        "    if name in ['classifier'] and isinstance(module, nn.Linear):\n",
        "        target_state_dict = module.state_dict()\n",
        "        bias = True if module.bias is not None else False\n",
        "        new_module = MixLinear(module.in_features, module.out_features, \n",
        "                               bias, target_state_dict['weight'], 0.5)\n",
        "        new_module.load_state_dict(target_state_dict)\n",
        "        setattr(model3, name, new_module)\n",
        "model3.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BiPcJFmqRNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize optimizer\n",
        "optimizer = AdamW(model3.parameters(), lr=2e-5, weight_decay=0.01, correct_bias=False)\n",
        "#scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)  # PyTorch scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0eQ8uJMBiDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "967234fd-4980-448d-b9ef-bc01d3a17bb4"
      },
      "source": [
        "#Train the model \n",
        "num_epochs=2\n",
        "\n",
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"gdrive/My Drive/Colab Notebooks/xlnet_tweet_undersamp_mix.bin\")\n",
        "model, train_loss_set, valid_loss_set = train(model=model3,\\\n",
        "                                              num_epochs=num_epochs,\\\n",
        "                                              optimizer=optimizer,\\\n",
        "                                              train_dataloader=train_dataloader,\\\n",
        "                                              valid_dataloader=validation_dataloader,\\\n",
        "                                              model_save_path=model_save_path,\\\n",
        "                                              device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.053820684883329604\n",
            "Valid loss: 0.05412008166313172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 1/2 [03:36<03:36, 216.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model at epoch 0 with validation loss of 0.05412008166313172\n",
            "\n",
            "\n",
            "Train loss: 0.05350122622869633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 2/2 [07:10<00:00, 215.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Valid loss: 0.05412008166313172\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjnfXmwfBmvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot loss vs number of epochs\n",
        "num_epochs = np.arange(len(train_loss_set))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5));\n",
        "ax.plot(num_epochs, np.array(train_loss_set), label=\"Train Loss\")\n",
        "ax.plot(num_epochs, np.array(valid_loss_set), 'g-', label=\"Valid Loss\")\n",
        "#ax1.plot(episode_record, lose_record, 'r-', label=\"Lose %\")\n",
        "ax.set_xlabel(\"Number of Epochs\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.set_title(\"Loss vs Number of Epochs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2awXoOHqbwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cwd = os.getcwd()\n",
        "model_save_path = output_model_file = os.path.join(cwd, \"gdrive/My Drive/Colab Notebooks/xlnet_tweet_undersampling_mix.bin\")\n",
        "model, start_epoch, lowest_eval_loss, train_loss_hist, valid_loss_hist = load_model(model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83YMdWP1qg6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to generate predictions on test data\n",
        "\n",
        "def generate_predictions(model, df, num_labels, device=\"cpu\", batch_size=32):\n",
        "  num_iter = math.ceil(df.shape[0]/batch_size)\n",
        "  \n",
        "  pred_probs = np.array([]).reshape(0, num_labels)\n",
        "  \n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  \n",
        "  for i in range(num_iter):\n",
        "    df_subset = df.iloc[i*batch_size:(i+1)*batch_size,:]\n",
        "    X = df_subset[\"features\"].values.tolist()\n",
        "    masks = df_subset[\"masks\"].values.tolist()\n",
        "    X = torch.tensor(X)\n",
        "    masks = torch.tensor(masks, dtype=torch.long)\n",
        "    X = X.to(device)\n",
        "    masks = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "      logits = model(input_ids=X, attention_mask=masks)\n",
        "      logits = logits.sigmoid().detach().cpu().numpy()\n",
        "      pred_probs = np.vstack([pred_probs, logits])\n",
        "  \n",
        "  return pred_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCbojiIEqjDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate predictions\n",
        "num_labels = len(label_cols)\n",
        "pred_probs = generate_predictions(model, test, num_labels, device=\"cuda\", batch_size=32)\n",
        "pred_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vByJtQlxqlSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=np.round(pred_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egdk5Co_qoZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Print accuracy score\n",
        "y_test=test.iloc[:,1:4].values\n",
        "accuracy_score(y_test,s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27_z9DJxcIVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Print classification report\n",
        "print('\\nClassification Report\\n')\n",
        "y_pred=np.round(pred_probs)\n",
        "print(classification_report(y_test, s, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVUfrPJXcHfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Print confusion matrix\n",
        "print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}